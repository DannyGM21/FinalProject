# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gi6lMSaGx-P1wFET-owk44zJbpL6jkUH
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
from sklearn.metrics import confusion_matrix
from wordcloud import WordCloud
import plotly.express as px
from streamlit_option_menu import option_menu
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from PIL import Image

# App Layout
st.set_page_config(page_title="Hate Speech Detection", layout="wide")

# Load model and tokenizer
@st.cache_resource
def load_model():
    model = AutoModelForSequenceClassification.from_pretrained("Danny1221Gm12/modelo-hate-speech-binary2")
    tokenizer = AutoTokenizer.from_pretrained("Danny1221Gm12/modelo-hate-speech-binary2")
    return model, tokenizer


model, tokenizer = load_model()

# Load dataset
@st.cache_data
def load_data():
    df = pd.read_csv("labeled_data.csv")
    df['label'] = df['class'].apply(lambda x: 1 if x == 0 else 0)
    return df

df = load_data()

# Prediction function
def predict(text):
    encoded = tokenizer(
        text,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=128
    )

    input_ids = encoded.get("input_ids")
    attention_mask = encoded.get("attention_mask")

    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)

    # Softmax y clase predicha
    probs = torch.nn.functional.softmax(outputs.logits, dim=1)
    pred_class = torch.argmax(probs, dim=1).item()
    confidence = probs[0][pred_class].item()

    label = "Hate Speech" if pred_class == 1 else "Not Hate Speech"
    return label, confidence

with st.sidebar:
    selected = option_menu("Main Menu", ["Inference", "Dataset Visualization", "Hyperparameter Tuning", "Model Analysis"],
                           icons=['chat', 'bar-chart', 'gear', 'clipboard-data'],
                           menu_icon="cast", default_index=0)

# Page 1 - Inference
if selected == "Inference":
    st.title("Hate Speech Detection")
    st.markdown("""Daniel Garnelo Martinez A00573086""")
    st.markdown("""Welcome to my final project for the "Modeling Learning with Artificial Intelligence" class""")
    st.markdown("For this project I chose to solve the problem of Hate Speech Detection ")
    st.markdown("I'm really exited, as the page is actually running, and the model is well trained" \
    ", however, the project had a lot of complication, particularly with the training of the model and the time " \
    "involved in it, but this will be discused later un the project, please enjoy the app.")
    st.title("Detector")
    st.markdown("First in the list, we have the detector, here you can write any english sentence and it will predict if the sentence is a hate message or not with the probability of being hate.")

    
    text = st.text_area("Enter a sentence:")
    if st.button("Predict"):
        label, confidence = predict(text)
        st.markdown(f"### Prediction: `{label}`")
        st.markdown(f"### Confidence: `{confidence:.2f}`")

# Page 2 - Dataset Visualization
elif selected == "Dataset Visualization":
    st.title("Dataset Visualization")
    st.markdown("First to start the understanding of the problem we have to look at the chosen dataset," \
    " I used a kaggle dataset, containing several tweeter posts with a lot of hate in them, you can find the dataset in this link: https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset")
    
    st.subheader("Class Distribution")
    counts = df['label'].value_counts()
    st.bar_chart(counts)
    st.markdown("Firts lets see the distribution of the dataset, we can se an extreme unbalance" \
    " in the dataset, as the class 0, containing all the hate messages, is disproportionally large" \
    " meanwhile the class 1 is smaller, we can also talk a little bit about our model, as the two classes " \
    " indicate we are using a binary classification model, as we need to differentiate between hate and no hate." \
    "The dataset had to be balanced, using and undersampling technique, ass the unbalance was so damatically" \
    " huge the undersampling was the best option as the information wouldnt be altered.")


    st.subheader("Token Length Distribution")
    df['length'] = df['tweet'].astype(str).apply(lambda x: len(x.split()))
    fig = px.histogram(df, x='length', nbins=30, title='Token Length Histogram')
    st.plotly_chart(fig)
    st.markdown("Then we can see the average lenght of the messages in the dataset," \
    " we can see the average lenght of the messages is 10 words.")


    st.subheader("Word Cloud")
    text = ' '.join(df['tweet'].astype(str))
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)
    st.markdown("Now we se a word cloud of our dataset, we can see the words that appear the most" \
    " in the messages, this words and slurs will be really important for the classification.")

# Page 3 - Hyperparameter Tuning
elif selected == "Hyperparameter Tuning":
    st.title("Hyperparameter Tuning")
    st.markdown("At first as I created the model the score in it was really bad, reaching an average of" \
    " 50%, so to make its predictions better I had to tune it to the limit, using the hyperparameters, getting " \
    " up to 80%, a good score, I used binary classification to do this.")
    st.markdown("However, the main barrier in the project was the running time, It wpuld take up to" \
    " 42 hours of running time to get the results and the complete training graphs, I managed to do it once" \
    ", however, I had to move and the session ended, deleting the files, I tried doing it again" \
    " but it was to late, so Ill just put the configuration, ignore the other graphs.")
    st.markdown("""
    Parameters:
    - Learning Rate: 2e-5 to 5e-5
    - Batch Size: 16, 32
    - Epochs: 3 (fixed for time constraints)
    - Dropout: 0.1 - 0.3
    
    Best configuration:
    - Learning rate: 3e-5
    - Batch size: 32
    - Dropout: 0.2
    """)
    st.image("optuna_trials_plot.png", caption="Performance over trials", use_column_width=True)

# Page 4 - Model Analysis
elif selected == "Model Analysis":
    st.title("Model Evaluation and Justification")
    st.markdown("""
    - **Model**: DistilBERT fine-tuned for binary classification.
    - **Reason**: Efficient and smaller transformer, suitable for limited compute.
    - **Challenges**: Imbalanced data, informal language, short texts.
    """)
    
    st.subheader("Classification Report")
    st.text(open("classification_report.txt").read())

    st.subheader("Confusion Matrix")

    


    st.subheader("Error Analysis")
    st.markdown("""
    - Some false positives were sarcastic or ambiguous.
    - False negatives included subtle hate phrases.
    - Improvement ideas:
        - Use of context-aware models.
        - Better annotations or data augmentation.
        - Ensemble approaches.
    """)
